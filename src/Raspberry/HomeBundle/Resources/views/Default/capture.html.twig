{% extends "RaspberryHomeBundle::layout.html.twig" %}

{% block title %}Webcam - {{ parent() }}{% endblock %}

{% block stylesheets %}
    {{ parent() }}
    {% stylesheets 'bundles/raspberryhome/css/capture.css' filter='cssrewrite' %}
<link rel="stylesheet" type="text/css" href="{{ asset_url }}" />
    {% endstylesheets %}
{% endblock %}

{% block raspberrycaptures_body %}

<h2>Capture webcam</h2>
<div class="row">
    <div class="col-md-12">
        <article>
            <p>Pour activer votre webcam et commencer les captures écrans, cliquer sur le bouton <strong>Autoriser</strong> présenté en partie haute de cette page par votre navigateur.</p>
        </article>
    </div>
</div>
<div class="row">
    <div class="col-md-8 col-xs-12 col-sm-12 col-lg-8">
        <video autoplay style="display: none;"></video>
        <canvas id="newPhoto"></canvas>
        <canvas id="oldPhoto"></canvas>
        <canvas id="savePhoto"></canvas>
    </div>
    <div class="col-md-4 col-xs-12 col-sm-12 col-lg-4">
        <div id="currentCaptureContainer" style="display: none;">
            <img id="currentCapture" alt="Capture en cours" class="img-responsive img-rounded" />
            <p class="text-center">Dernière image capturée</p>
        </div>
    </div>
</div>
<div class="row">
    <div id="infos" class="text-danger"></div>
</div>

<script>
    $(document).ready(function () {
        var hasGetUserMedia = function () {
            // Returns true if supported
            return !!(navigator.getUserMedia || navigator.webkitGetUserMedia ||
                    navigator.mozGetUserMedia || navigator.msGetUserMedia);
        };

        var onSuccess = function (stream) {
            // If we can stream from camera
            var source;

            // Get the stream. This goes to the video tag.
            if (window.URL) {
                source = window.URL.createObjectURL(stream);
            }
            else {
                source = stream; // Opera and Firefox
            }

            // Set up video tag
            video.autoplay = true;
            video.src = source;

            // We try to find motion in every X second
            setInterval(function () {
                motionDetector();
            }, sampling);

        };

        var onError = function () {
            // If we fail (not supported, no camera etc.)
            alert("Pas de flux trouvé. Veuillez réessayer.");
        };

        var grayScale = function (context, canvas) {
            // Make canvas gray
            var imgData = context.getImageData(0, 0, canvas.width, canvas.height);
            var pixels = imgData.data;

            for (var i = 0, n = pixels.length; i < n; i += 4) {
                var grayscale = pixels[i] * .3 + pixels[i + 1] * .59 + pixels[i + 2] * .11;
                pixels[i] = grayscale; // Red
                pixels[i + 1] = grayscale; // Green
                pixels[i + 2] = grayscale; // Blue
            }

            // Redraw the image in black and white
            context.putImageData(imgData, 0, 0);
        }

        var colorMeanValue = function (context, canvas) {
            // Calculate the mean color value of the pixels also we collect all the pixel's colors in array
            var imgData = context.getImageData(0, 0, canvas.width, canvas.height);
            var pixels = imgData.data;
            var colorList = new Array();
            var colorSum = 0;

            for (var i = 0, n = pixels.length; i < n; i += 4) {
                colorList.push(pixels[i + 2]);
                colorSum += pixels[i + 2];
            }

            return [Math.round(colorSum / (sampleDimension * sampleDimension)), colorList];
        }

        var bits = function (colorMean) {
            // Represent the the higher than the mean value colors as 1 others as 0
            var bits = new Array();
            var colors = colorMean[1];

            for (var i = 0; i < (sampleDimension * sampleDimension) ; i++) {
                if (colors[i] >= colorMean[0]) {
                    bits[i] = 1;
                }
                else {
                    bits[i] = 0;
                }

            }
            return bits;

        }

        var hammeringDistance = function (bits1, bits2) {
            // Calculating the hammering distance of two set of binary data
            var hD = 0;

            console.log(bits1)
            console.log(bits2)

            for (i = 0; i < (sampleDimension * sampleDimension) ; i++) {
                if (bits1[i] != bits2[i]) {
                    hD++;
                }
            }
            return hD;
        }

        var saveImage = function (canvasToSave) {
            // Get data
            var dataUrl = canvasToSave.toDataURL();

            // Update the current capture image source
            currentCapture.src = dataUrl;
            currentCaptureContainer.style.display = "block";

            // Call the service to save the image to a file on the server
            $.ajax({
                type: 'POST',
                url: '{{ path("raspberry_api_images_upload") }}',
                cache: false,
                dataType: 'text',
                data: {
                    base64: dataUrl
                },
                success: function (data, textStatus, jqXHR) {
                    
                },
                error: function (jqXHR, textStatus, errorThrown) {
                    $('#infos').html(errorThrown);
                },
            });
        }

        var motionDetector = function () {
            // This function creates 3 canvas data. The newest image, the newest in savable format and keeps the one before this if needed. This function
            // depends on the first variable as there is no point of comparsion at first iteration.

            // We make the three canvases
            ctxOld.drawImage(newPhoto, 0, 0, sampleDimension, sampleDimension);
            ctxNew.drawImage(video, 0, 0, sampleDimension, sampleDimension);
            ctxSave.drawImage(video, 0, 0, savePhoto.width, savePhoto.height);

            // Convert the newest image to gray scale. There is no need to do this to the second one as it will become this one in the next round
            grayScale(ctxNew, newPhoto);

            if (!first) {
                // Start detecting motion (detecting difference between images 1 second from eachother
                hD = hammeringDistance
                (
                    bits(colorMeanValue(ctxNew, newPhoto)),
                    bits(colorMeanValue(ctxOld, oldPhoto))
                )

                console.log(hD);

                if (hD > sensitivity) {
                    saveImage(savePhoto);
                }

            } else { first = false; }
        }

        /* After all those functions lets start setting up the program */

        // Set up elements. Should be a ini() but I don't care right now
        var video = $('video').get(0); // The video tag
        var newPhoto = $('#newPhoto').get(0); // The newest image's canvas
        var oldPhoto = $('#oldPhoto').get(0); // The older image's canvas
        var savePhoto = $('#savePhoto').get(0); // The possible saved image's canvas
        var currentCaptureContainer = $('#currentCaptureContainer').get(0); // The container of the last capture image
        var currentCapture = $('#currentCapture').get(0); // The image where the last capture is shown

        var ctxNew = newPhoto.getContext('2d'); // The latest image from video prepared for comparison
        var ctxOld = oldPhoto.getContext('2d'); // Copy of the older image from video prepared for comparison
        var ctxSave = savePhoto.getContext('2d'); // The latest image from video in full size and color

        var sampling = 1000; // How much time needed between samples in milliseconds

        var sensitivity = 10; // How sensitive the detection. 1 is the minimum 5 is ideal, more might be good at worst cameras where noise is present even when there is no movement

        var first = true; // True if it was the first iteration of the code

        var sampleDimension = 8; // Size of the samples. Small square image based on camera stream. The bigger the more resource it needs. 8 works perfectly.

        // We need this so we can use the videoWidth and ...Height, also we setup canvas sizes here, after we have video data
        video.addEventListener('loadedmetadata', function () {
            console.log(video.videoWidth + ":" + video.videoHeight)
            video.style.width = "100%";
            video.style.height = ((video.videoHeight / video.videoWidth) * 100).toString() + "%";
            video.style.display = "block";
            oldPhoto.width = oldPhoto.height = newPhoto.width = newPhoto.height = sampleDimension;
            savePhoto.width = video.videoWidth;
            savePhoto.height = video.videoHeight;
        });

        // Start the whole magic
        if (hasGetUserMedia()) {
            // Working or not working? That's the question...
            navigator.getUserMedia || (navigator.getUserMedia = navigator.mozGetUserMedia || navigator.webkitGetUserMedia || navigator.msGetUserMedia);
            navigator.getUserMedia({ video: true, toString: function () { return "video"; } }, onSuccess, onError);
        }
        else {
            // No support
            alert("getUserMedia() n'est pas supporté par votre navigateur. Veuillez essayer avec Chrome.");
        }
    });
</script>
{% endblock %}